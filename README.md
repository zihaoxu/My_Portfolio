# Zihao's Portfolio
Welcome to my data science Portfolio! This repository is designed to give you a better sense of who I am, what I am capable of, and what I am passionate about. I am currently looking for a summer internship in data science. If you are interested in learning more about me, please take a look at my [resume](https://goo.gl/gvVqxW) or visit my [LinkedIn](https://www.linkedin.com/in/zihao-xu/). I can also be reached at zxql2015@mymail.pomona.edu through email.

## Basic information  
### Work Experience:  
- Business and Credit Risk Analyst Intern at Scratch Financial, LLC  
- Summer Researcher at Pomona College Mathematics Department  
- Research Assistant at Pomona College Economics Department  
- Quantitative Analyst Intern at Guotai Junan Securities Co., Ltd  

### Related Courses  
#### Computational Statistics (https://goo.gl/rfusFE)  
- Data Visualization and Wrangling w/ ggplot2 and dplyr  
- Simulation and Permutation test  
#### Big Data - Platform/Application (https://goo.gl/k7wRdq)  
- WordCount with MapReduce  
- PageRank with MapReduce  
#### Econometrics (https://goo.gl/gqcrjv)  
- Benchmark Model and Institutional Growth Model on GDP  
- Charitable Giving Model on household donation  


## On-going Projects  
### Bag of Little Random Forests (BLRF)  
Random Forests (Breiman, 2001) are an ensemble method that utilizes a number of deci- sion trees to make robust predictions in both regression and classification settings. However, the process of bootstrap aggregation, the mechanism underlying the Random Forests algo- rithm, requires each decision tree to physically store and perform computations on data sets of the same size as the training data set. This situation is oftentimes impractical given the large size of data sets nowadays. To address this problem, we introduce the Bag of Little Ran- dom Forests (BLRF), a new algorithm that combines the Random Forests with the Bag of Little Bootstraps (Kleiner et al., 2014) resampling method, aiming to achieve a better computational profile while producing predictions with comparable accuracy as those of the Random Forests.

#### Research Paper and Presentation  
Bag of Little Random Forests - Zihao Xu, Dr. Johanna Hardin: https://goo.gl/gJHqar  
Project PPT: https://goo.gl/KJ34uY  
Project Poster: https://goo.gl/LmkZu4  
Project Visualizations: https://goo.gl/nU1gDC  

### Data Science Toolbox  
Python pipelines built for summary statistics, data cleaning and machine learning & parameter tuning.  
**Link**: https://goo.gl/ADVyoY  

### Yelp Review Sentiment Analysis  
In this project, we explored and performed sentiment analysis on reviews obtained from the Yelp Data Challenge. We explored temporal trends of review sentiment as well as interesting interactions between review tags. We also build a sentiment predictor for reviews solely based on text analysis. The resulting interactive module allows us to assess the sentiment of a unlabeled piece of review text with a confidence score.

#### Project Paper & Presentation  
Paper: https://goo.gl/s7K1uA  
Presentation: https://goo.gl/cMzfWB  

### KKBox Churning Prediction Kaggle Challenge  
In this project, we aim to document our methodologies in approaching the KKBox Churning Prediction Challenge. This challenge is essentially a classification problem, but the response variable is highly imbalanced. In the below sections, we will describe and visually explore the data sets. Then we will talk about several machine learning models we employed that are highly suitable for handling imbalanced data. Our current ranking on Kaggle is 136 out of 535, achieved by the XGBoost model.

#### Project Paper & Presentation  
Paper: https://goo.gl/en3cSV  
Presentation: https://goo.gl/YLjTv9  

## Past Experiences  
### Yelp - Zillow Data Analytics - jac_project   
The purpose of the project was to explore and analyze the interaction between Zillow hosing price index and Yelp restaurant ratings to identify temporal trends. We merged and integrated the datasets by geospatial locations and performed various analyses. One of our most interesting findings was that, the most expensive restaurants, if located at a relative poor neighborhood, have experienced a significant decreasing trend in rating; however, the ratings remained constant for those located at a relatively rich neighborhood.  
**Visualizations:**  https://goo.gl/CvJefP  


### Statsketball Challenge - ASA  
In this project, we aim to predict 2017 NCAA March Madness basketball game results using Support Vector Machine. We scraped data from two sources: Kenpom and Sport-references, cleaned and wrangled the data, and trained a SVM model to predict the actual game results, yielding a accuracy of 84.375% on out of sample data.  
**Project Summary:**  https://goo.gl/fEBRNx  

### Expedia Challenge - UCLA DataFest  
Using the dataset from Expedia, we segmented the market by families with varying number of children and explored the different behaviors of these segments. Using visualization techniques like heatmap and geomap, we were able to discover differences in travel planning habits, popular destinations of each group, as well as identifying the geographical distribution of large/small families to allow for better targeted promotion.  
**Project Presentation:**  https://goo.gl/4MmRJx  




