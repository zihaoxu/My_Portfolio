{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# important packages to import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys, os\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing, cross_validation, svm\n",
    "from sklearn.cross_validation import cross_val_score, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame Summary and inital cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# holistic summary of the given data set. \n",
    "# \"remove_bad_rowCol\" can be turned on to remove non-informative col / row\n",
    "def holistic_summary(df, remove_bad_rowCol = False, verbose = True):\n",
    "    # remove non-informative columns\n",
    "    if(remove_bad_rowCol):\n",
    "        df = df.drop(df.columns[df.isnull().sum() >= .9 * len(df)], axis = 1)\n",
    "        df = df.drop(df.index[df.isnull().sum(axis = 1) >= .5* len(df.columns)], axis = 0)\n",
    "        \n",
    "    # fix column names:\n",
    "    df.columns = [c.replace(\" \", \"_\").lower() for c in df.columns]\n",
    "    \n",
    "    print('***************************************************************')\n",
    "    print('Begin holistic summary: ')\n",
    "    print('***************************************************************\\n')\n",
    "    \n",
    "    print('Dimension of df: ' + str(df.shape))\n",
    "    print('Percentage of good observations: ' + str(1 - df.isnull().any(axis = 1).sum()/len(df)))\n",
    "    print('---------------------------------------------------------------\\n')\n",
    "    \n",
    "    print(\"Rows with nan values: \" + str(df.isnull().any(axis = 1).sum()))\n",
    "    print(\"Cols with nan values: \" + str(df.isnull().any(axis = 0).sum()))\n",
    "    print('Breakdown:')\n",
    "    print(df.isnull().sum()[df.isnull().sum()!=0])\n",
    "    print('---------------------------------------------------------------\\n')\n",
    "    \n",
    "    print('Columns details: ')\n",
    "    print('Columns with known dtypes: ')\n",
    "    good_cols = pd.DataFrame(df.dtypes[df.dtypes!='object'], columns = ['type'])\n",
    "    good_cols['nan_num'] = [df[col].isnull().sum() for col in good_cols.index]\n",
    "    good_cols['unique_val'] = [df[col].nunique() for col in good_cols.index]\n",
    "    good_cols['example'] = [df[col][1] for col in good_cols.index]\n",
    "    good_cols = good_cols.reindex(good_cols['type'].astype(str).str.len().sort_values().index)\n",
    "    print(good_cols)\n",
    "    print('\\n')\n",
    "    \n",
    "    try:\n",
    "        print('Columns with unknown dtypes:')\n",
    "        bad_cols = pd.DataFrame(df.dtypes[df.dtypes=='object'], columns = ['type'])\n",
    "        bad_cols['nan_num'] = [df[col].isnull().sum() for col in bad_cols.index]\n",
    "        bad_cols['unique_val'] = [df[col].nunique() for col in bad_cols.index]\n",
    "        bad_cols['example(sliced)'] = [str(df[col][1])[:10] for col in bad_cols.index]\n",
    "        bad_cols = bad_cols.reindex(bad_cols['example(sliced)'].str.len().sort_values().index)\n",
    "        print(bad_cols)\n",
    "    except Exception as e:\n",
    "        print('No columns with unknown dtypes!')\n",
    "    print('_______________________________________________________________\\n\\n\\n')\n",
    "    #if not verbose: enablePrint()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************************************************\n",
      "Begin holistic summary: \n",
      "***************************************************************\n",
      "\n",
      "Dimension of df: (336776, 20)\n",
      "Percentage of good observations: 0.971999192341\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Rows with nan values: 9430\n",
      "Cols with nan values: 6\n",
      "Breakdown:\n",
      "dep_time     8255\n",
      "dep_delay    8255\n",
      "arr_time     8713\n",
      "arr_delay    9430\n",
      "tailnum      2512\n",
      "air_time     9430\n",
      "dtype: int64\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Columns details: \n",
      "Columns with known dtypes: \n",
      "                   type  nan_num  unique_val  example\n",
      "unnamed:_0        int64        0      336776      2.0\n",
      "year              int64        0           1   2013.0\n",
      "month             int64        0          12      1.0\n",
      "day               int64        0          31      1.0\n",
      "sched_dep_time    int64        0        1021    529.0\n",
      "sched_arr_time    int64        0        1163    830.0\n",
      "flight            int64        0        3844   1714.0\n",
      "distance          int64        0         214   1416.0\n",
      "hour              int64        0          20      5.0\n",
      "minute            int64        0          60     29.0\n",
      "dep_time        float64     8255        1318    533.0\n",
      "dep_delay       float64     8255         527      4.0\n",
      "arr_time        float64     8713        1411    850.0\n",
      "arr_delay       float64     9430         577     20.0\n",
      "air_time        float64     9430         509    227.0\n",
      "\n",
      "\n",
      "Columns with unknown dtypes:\n",
      "             type  nan_num  unique_val example(sliced)\n",
      "carrier    object        0          16              UA\n",
      "origin     object        0           3             LGA\n",
      "dest       object        0         105             IAH\n",
      "tailnum    object     2512        4043          N24211\n",
      "time_hour  object        0        6936      2013-01-01\n",
      "_______________________________________________________________\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "flights = pd.read_csv('../Datasets/flights.csv')\n",
    "flights = holistic_summary(boston, remove_bad_rowCol = True, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame cleaning and type fixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fixing dtypes: time and numeric variables\n",
    "def fix_dtypes(df, time_cols, num_cols):\n",
    "    \n",
    "    print('***************************************************************')\n",
    "    print('Begin fixing data types: ')\n",
    "    print('***************************************************************\\n')\n",
    "    \n",
    "    def fix_time_col(df, time_cols):\n",
    "        for time_col in time_cols:\n",
    "            df[time_col] = pd.to_datetime(df[time_col], errors = 'coerce')\n",
    "        print('---------------------------------------------------------------')\n",
    "        print('The following time columns has been fixed: ')\n",
    "        print(time_cols)\n",
    "        print('---------------------------------------------------------------\\n')\n",
    "\n",
    "    def fix_factor_col(df):\n",
    "        categorical_col = []\n",
    "        for col in df.columns:\n",
    "            if (df[col].nunique()<12) & (df[col].nunique()<len(df)/10):\n",
    "                df[col] = df[col].astype('category')\n",
    "                categorical_col.append(col)\n",
    "        print('---------------------------------------------------------------')\n",
    "        print('The following category columns has been fixed: ')\n",
    "        print(categorical_col)\n",
    "        print('---------------------------------------------------------------\\n')\n",
    "\n",
    "    def fix_num_col(df, num_cols):\n",
    "        for col in num_cols:\n",
    "            df[col] = pd.to_numeric(df[col], errors = 'coerce')\n",
    "        print('---------------------------------------------------------------')\n",
    "        print('The following number columns has been fixed: ')\n",
    "        print(num_cols)\n",
    "        print('---------------------------------------------------------------\\n')\n",
    "        \n",
    "    if(len(num_cols) > 0):\n",
    "        fix_num_col(df, num_cols)\n",
    "    fix_time_col(df, time_cols)\n",
    "    #fix_factor_col(df)\n",
    "    #fix_string_col(df)\n",
    "    print('---------------------------------------------------------------')\n",
    "    print('Final data types:')\n",
    "    result = pd.DataFrame(df.dtypes, columns = ['type'])\n",
    "    result = result.reindex(result['type'].astype(str).str.len().sort_values().index)\n",
    "    print(result)\n",
    "    print('_______________________________________________________________\\n\\n\\n')\n",
    "    return df\n",
    "\n",
    "# fix nan values \n",
    "def fix_nan(df, how = 'partial'):\n",
    "    \n",
    "    print('***************************************************************')\n",
    "    print('Begin fixing nans: ')\n",
    "    print('***************************************************************\\n')\n",
    "    if(how == 'partial'):     \n",
    "        print('The following columns are removed due to nan1: ')\n",
    "        print(df.columns[df.isnull().sum() >= .5 * len(df)])\n",
    "        df = df.drop(df.columns[df.isnull().sum() >= .5 * len(df)], axis = 1)\n",
    "    elif(how == 'all'):\n",
    "        print('The following columns are removed due to nan2: ')\n",
    "        print(df.columns[df.isnull().sum() == len(df)])\n",
    "        df = df.drop(df.columns[df.isnull().sum() == len(df)], axis = 1)\n",
    "    print('_______________________________________________________________\\n\\n\\n')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************************************************************\n",
      "Begin fixing nans: \n",
      "***************************************************************\n",
      "\n",
      "The following columns are removed due to nan1: \n",
      "Index([], dtype='object')\n",
      "_______________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "***************************************************************\n",
      "Begin fixing data types: \n",
      "***************************************************************\n",
      "\n",
      "---------------------------------------------------------------\n",
      "The following time columns has been fixed: \n",
      "['time_hour']\n",
      "---------------------------------------------------------------\n",
      "\n",
      "---------------------------------------------------------------\n",
      "Final data types:\n",
      "                          type\n",
      "unnamed:_0               int64\n",
      "year                     int64\n",
      "month                    int64\n",
      "day                      int64\n",
      "hour                     int64\n",
      "sched_dep_time           int64\n",
      "distance                 int64\n",
      "sched_arr_time           int64\n",
      "minute                   int64\n",
      "flight                   int64\n",
      "carrier                 object\n",
      "tailnum                 object\n",
      "origin                  object\n",
      "dest                    object\n",
      "air_time               float64\n",
      "arr_delay              float64\n",
      "dep_delay              float64\n",
      "dep_time               float64\n",
      "arr_time               float64\n",
      "time_hour       datetime64[ns]\n",
      "_______________________________________________________________\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "flights = fix_nan(flights, 'partial')\n",
    "flights = fix_dtypes(flights, time_cols = ['time_hour'], num_cols = [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def k_fold_cross_validation (clf, X_train, y_train, verbose = True, k = 5):\n",
    "    clf.fit(X_train, y_train) # fit the model\n",
    "    cv = KFold(X_train.shape[0], 5, shuffle = True)\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv = cv) # 5-fold cross_validation\n",
    "    \n",
    "    if verbose == True: #if we want to print status\n",
    "        print(\"Coefficient of determination on training set:\", clf.score(X_train, y_train))\n",
    "        print(\"Average coefficient of determination using 5-fold crossvalidation:\", np.mean(scores))\n",
    "        print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    # returns the mean score and 2 sigma\n",
    "    return np.mean(scores), scores.std() * 2\n",
    "\n",
    "def label_encode(df, col_encode):\n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    for col in col_encode:\n",
    "        df[col] = encoder.fit_transform(df[col])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
